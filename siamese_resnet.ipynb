{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import albumentations\n",
    "from albumentations import torch as AT\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import PIL.ImageOps    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "28f2e0322b61e9ccf6ebefa5416e7243b6a696a6"
   },
   "outputs": [],
   "source": [
    "#!pip install pretrainedmodels > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "09ef92ab00e546fb4074ba9fad72411b5e3b947e"
   },
   "source": [
    "## Siamese Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "\n",
    "class SiameseDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,datafolder, df, bbox_df, datatype='train', transform = None):\n",
    "        self.datafolder = datafolder\n",
    "        self.df = df\n",
    "        self.bbox_df = bbox_df\n",
    "        self.datatype = datatype\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        # not selecting 'new_whale' for anchor image.\n",
    "        img0_idx = random.choice(self.df[self.df.Id != 'new_whale'].index.values)\n",
    "        \n",
    "        # we need to make sure approx 50% of images are in the same class\n",
    "        should_get_same_class = random.randint(0,1)\n",
    "        if should_get_same_class:\n",
    "            img1_idx = random.choice(self.df[self.df.Id == self.df.Id[img0_idx]].index.values) \n",
    "        else:\n",
    "            img1_idx = random.choice(self.df[self.df.Id != self.df.Id[img0_idx]].index.values)\n",
    "        \n",
    "        img0_path = self.df.loc[img0_idx,'Image']\n",
    "        img1_path = self.df.loc[img1_idx,'Image']\n",
    "        \n",
    "        bbox0 = bbox_df.loc[bbox_df.Image==img0_path,:].values[0,1:]\n",
    "        bbox1 = bbox_df.loc[bbox_df.Image==img1_path,:].values[0,1:]\n",
    "        img0_pil = Image.open(os.path.join(self.datafolder, img0_path)).crop(bbox0).convert('RGB')\n",
    "        img1_pil = Image.open(os.path.join(self.datafolder, img1_path)).crop(bbox1).convert('RGB')\n",
    "        img0 = np.array(img0_pil)\n",
    "        img1 = np.array(img1_pil)\n",
    "             \n",
    "        image0 = self.transform(image=img0)['image']\n",
    "        image1 = self.transform(image=img1)['image']\n",
    "        #plt.imshow(image0)\n",
    "        return image0, image1 , torch.from_numpy(np.array([int(self.df.Id[img0_idx] != self.df.Id[img1_idx])],dtype=np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(self.df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize the image pair in order to verify the function working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # not selecting 'new_whale' for anchor image.\n",
    "# #index\n",
    "# df = pd.read_csv(\"train.csv\")\n",
    "# bbox_df = pd.read_csv(\"bounding_boxes.csv\")\n",
    "# img0_idx = random.choice(df[df.Id != 'new_whale'].index.values)\n",
    "\n",
    "# # we need to make sure approx 50% of images are in the same class\n",
    "# should_get_same_class = random.randint(0,1)\n",
    "# print(should_get_same_class)\n",
    "# if should_get_same_class:\n",
    "#     img1_idx = random.choice(df[df.Id == df.Id[img0_idx]].index.values) \n",
    "# else:\n",
    "#     img1_idx = random.choice(df[df.Id != df.Id[img0_idx]].index.values)\n",
    "\n",
    "# #print('0-',img0,'    1-',img1)\n",
    "# img0_path = df.loc[img0_idx,'Image']\n",
    "# img1_path = df.loc[img1_idx,'Image']\n",
    "\n",
    "# bbox0 = bbox_df.loc[bbox_df.Image==img0_path,:].values[0,1:]\n",
    "# bbox1 = bbox_df.loc[bbox_df.Image==img1_path,:].values[0,1:]\n",
    "# img0_pil = Image.open(os.path.join(\"train\", img0_path)).crop(bbox0).convert('RGB')\n",
    "# img1_pil = Image.open(os.path.join(\"train\", img1_path)).crop(bbox1).convert('RGB')\n",
    "# #img0 = cv2.cvtColor(np.array(img0_pil), cv2.COLOR_BGR2RGB)\n",
    "# img0 = np.array(img0_pil)\n",
    "# img1 = np.array(img1_pil) \n",
    "# #img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "# data_transforms = albumentations.Compose([\n",
    "#     albumentations.Resize(RESIZE_H, RESIZE_W),\n",
    "#     albumentations.HorizontalFlip(),\n",
    "#     albumentations.OneOf([\n",
    "#         albumentations.RandomContrast(),\n",
    "#         albumentations.RandomBrightness(),\n",
    "#         albumentations.Blur()\n",
    "#     ]),\n",
    "#     albumentations.ShiftScaleRotate(rotate_limit=10, scale_limit=0.15),\n",
    "#     #albumentations.JpegCompression(80),\n",
    "#     albumentations.HueSaturationValue(),\n",
    "#     albumentations.Normalize(),\n",
    "#     #AT.ToTensor()\n",
    "# ])\n",
    "# image0 = data_transforms(image=img0)['image']\n",
    "# image1 = data_transforms(image=img1)['image']\n",
    "\n",
    "# f = plt.figure()\n",
    "# f.add_subplot(2,2, 1)\n",
    "# plt.imshow(img0) \n",
    "# f.add_subplot(2,2, 2)\n",
    "# plt.imshow(img1) \n",
    "# f.add_subplot(2,2, 3)\n",
    "# plt.imshow(image0) \n",
    "# f.add_subplot(2,2, 4)\n",
    "# plt.imshow(image1) \n",
    "# plt.show(block=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac19e129b87b868817bf6be7187eebe8d64fe278"
   },
   "source": [
    "## EembeddingNet ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "5f616d0542e0c6057d9b47b7873f35d295845c51"
   },
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        \n",
    "        self.model = nn.Sequential(resnet.conv1, resnet.bn1,resnet.relu, resnet.maxpool,resnet.layer1,resnet.layer2,resnet.layer3,resnet.layer4,resnet.avgpool)#,resnet.fc)\n",
    "        # Fix blocks\n",
    "        fixed_blocks = 1\n",
    "        for p in self.model[0].parameters(): p.requires_grad=False\n",
    "        for p in self.model[1].parameters(): p.requires_grad=False\n",
    "        if fixed_blocks >= 3:\n",
    "            for p in self.model[6].parameters(): p.requires_grad=False\n",
    "        if fixed_blocks >= 2:\n",
    "            for p in self.model[5].parameters(): p.requires_grad=False\n",
    "        if fixed_blocks >= 1:\n",
    "            for p in self.model[4].parameters(): p.requires_grad=False\n",
    "\n",
    "        def set_bn_fix(m):\n",
    "            classname = m.__class__.__name__\n",
    "            if classname.find('BatchNorm') != -1:\n",
    "                for p in m.parameters(): p.requires_grad=False\n",
    "\n",
    "        self.model.apply(set_bn_fix)\n",
    "        \n",
    "        resnet.fc = nn.Linear(2048, 5004, bias=True)\n",
    "        self.last_layer = resnet.fc\n",
    "        \n",
    "\n",
    "    def forward(self, x):    \n",
    "        x = self.model(x)\n",
    "        x = x.view(-1, 2048)\n",
    "        return self.last_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "35145847dcc32c890310e6107a72e1c97681ca93"
   },
   "source": [
    "## Siamese Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "78499a85cdd2deaae85e13f866940deee69d25f1"
   },
   "outputs": [],
   "source": [
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self, embedding_net):\n",
    "        super(SiameseNet, self).__init__()\n",
    "        self.embedding_net = embedding_net\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        output1 = self.embedding_net(x1)\n",
    "        output2 = self.embedding_net(x2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4a6a8a3ebba6a6b0735826fdc37ba96d7af0c021"
   },
   "source": [
    "## ContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "f67a79ffa6de14baa3932e443729423a5a18d708"
   },
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss\n",
    "    Takes embeddings of two samples and a target label == 1 if samples are from the same class and label == 0 otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.eps = 1e-9\n",
    "\n",
    "    def forward(self, output1, output2, target, size_average=True):\n",
    "        distances = (output2 - output1).pow(2).sum(1)  # squared distances\n",
    "        losses = 0.5 * (target.float() * distances +\n",
    "                        (1 + -1 * target).float() * F.relu(self.margin - (distances + self.eps).sqrt()).pow(2))\n",
    "        return losses.mean() if size_average else losses.sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "01fb618bb8f7b648e89f80eade7b1915da162a89"
   },
   "source": [
    "## Data Path and Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "a4e1811b0ac2a583287ccb68d9092ce61e5478c6"
   },
   "outputs": [],
   "source": [
    "train_full = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "id_counts = train_full.Id.value_counts()\n",
    "\n",
    "valid_df = train_full.loc[train_full.Id.isin(id_counts[id_counts>5].index.values),:].sample(frac=0.1)\n",
    "\n",
    "train_df = train_full.loc[~train_full.index.isin(valid_df.index.values),:]\n",
    "\n",
    "test_df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "bbox_df = pd.read_csv(\"bounding_boxes.csv\")\n",
    "\n",
    "RESIZE_H = 224\n",
    "RESIZE_W = 224\n",
    "\n",
    "data_transforms = albumentations.Compose([\n",
    "    albumentations.Resize(RESIZE_H, RESIZE_W),\n",
    "    albumentations.HorizontalFlip(),\n",
    "    albumentations.OneOf([\n",
    "        albumentations.RandomContrast(),\n",
    "        albumentations.RandomBrightness(),\n",
    "        albumentations.Blur()\n",
    "    ]),\n",
    "    albumentations.ShiftScaleRotate(rotate_limit=10, scale_limit=0.15),\n",
    "    albumentations.JpegCompression(80),\n",
    "    albumentations.HueSaturationValue(),\n",
    "    albumentations.Normalize(),\n",
    "    AT.ToTensor()\n",
    "])\n",
    "\n",
    "data_transforms_test = albumentations.Compose([\n",
    "    albumentations.Resize(RESIZE_H, RESIZE_W),\n",
    "    albumentations.Normalize(),\n",
    "    AT.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "49a95f7232d5eb85f611d863bf8f98558a480870"
   },
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "adbf832bab060df5fd960f1e605b3c7a0f0d9306"
   },
   "outputs": [],
   "source": [
    "train_dataset = SiameseDataset(datafolder=\"train/\", \n",
    "                                 df=train_df, bbox_df=bbox_df, datatype='train', transform = data_transforms)\n",
    "valid_dataset = SiameseDataset(datafolder=\"train/\", \n",
    "                                 df=valid_df, bbox_df=bbox_df, datatype='train', transform = data_transforms)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=0,\n",
    "                        batch_size=64)\n",
    "\n",
    "valid_dataloader = DataLoader(train_dataset,\n",
    "                        shuffle=False,\n",
    "                        num_workers=0,\n",
    "                        batch_size=32)\n",
    "\n",
    "# embed = EmbeddingNet().cuda()\n",
    "# net = SiameseNet(embed).cuda()\n",
    "embed = EmbeddingNet()#.cuda()\n",
    "net = SiameseNet(embed)#.cuda()\n",
    "criterion = ContrastiveLoss(margin=0.2)\n",
    "optimizer = optim.Adam(net.parameters(),lr = 0.0005 )\n",
    "\n",
    "counter = []\n",
    "loss_history = [] \n",
    "iteration_number= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_net(net, path):\n",
    "    torch.save(net, path)\n",
    "    print(\"Checkpoint saved to {}\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "008352873873428247d277ab5fe6635cb38d3255"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f9da56ec7ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mimg0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#         img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/anaconda3/envs/py3iaml/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/anaconda3/envs/py3iaml/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a9a13c93dd37>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mimg1_pil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatafolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg1_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mimg0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg0_pil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mimg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1_pil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mimage0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_num = 3\n",
    "loss = 0\n",
    "tol_loss = []\n",
    "path_best = 'best_net.pth'\n",
    "path_cur = 'cur_net.pth'\n",
    "total_num_val = len(valid_df)\n",
    "\n",
    "for epoch in range(0,epoch_num):\n",
    "    # train\n",
    "    net.train()\n",
    "    for i, data in enumerate(train_dataloader,0):\n",
    "        img0, img1 , label = data\n",
    "#         img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
    "        img0, img1 , label = img0, img1 , label\n",
    "        optimizer.zero_grad()\n",
    "        output1,output2 = net(img0,img1)\n",
    "        loss_contrastive = criterion(output1,output2,label)\n",
    "        loss_contrastive.backward()\n",
    "        optimizer.step()\n",
    "        if i %100 == 0 :\n",
    "            print(\"Epoch number {} \\t Iteration number {} \\t Current loss {}\\n\".format(epoch,iteration_number,loss_contrastive.item()))\n",
    "            iteration_number +=10\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss_contrastive.item())\n",
    "\n",
    "\n",
    "    # validate\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        loss = 0\n",
    "        for i, data in enumerate(valid_dataloader):\n",
    "            val_img0, val_img1, val_label = data\n",
    "            val_output1,val_output2 = net(val_img0, val_img1)\n",
    "            val_loss = criterion(val_output1,val_output2,val_label)\n",
    "            loss += val_loss.item()\n",
    "        \n",
    "        print(\"Epoch number {} \\t Val loss {}\\n\".format(epoch, loss))\n",
    "        avg_loss = loss/total_num_val\n",
    "        tol_loss.append(avg_loss)\n",
    "        if avg_loss < min(tol_loss):\n",
    "            save_net(net, path_best)\n",
    "            \n",
    "        save_net(net, path_cur)\n",
    "        \n",
    "# show_plot(counter,loss_history) \n",
    "# show_plot(epoch = 50, tol_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "1677b335e684686e3e631583a760d449d03f04fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseNet(\n",
       "  (embedding_net): EmbeddingNet(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    )\n",
       "    (last_layer): Linear(in_features=2048, out_features=5004, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up for evaluation\n",
    "siamese_net = torch.load(\"best_net.pth\")\n",
    "state_dict = siamese_net.state_dict()\n",
    "embed_net = EmbeddingNet()\n",
    "temp_dict = {}\n",
    "for key in state_dict.keys():\n",
    "    if key.startswith(\"embedding_net\"):\n",
    "        temp_dict[key[14:len(key)]] = state_dict[key]\n",
    "embed_net.load_state_dict(temp_dict)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
